cmake==3.27.4.1
fairscale==0.4.13
filelock==3.12.3
fire==0.5.0
Jinja2==3.1.2
lit==16.0.6
-e git+https://github.com/boringlee24/llama_inference.git@5e58d9b21ebb9090d25591e881da094f0425baf5#egg=llama
MarkupSafe==2.1.3
mpmath==1.3.0
networkx==3.1
numpy==1.25.2
nvidia-cublas-cu11==11.10.3.66
nvidia-cuda-cupti-cu11==11.7.101
nvidia-cuda-nvrtc-cu11==11.7.99
nvidia-cuda-runtime-cu11==11.7.99
nvidia-cudnn-cu11==8.5.0.96
nvidia-cufft-cu11==10.9.0.58
nvidia-curand-cu11==10.2.10.91
nvidia-cusolver-cu11==11.4.0.1
nvidia-cusparse-cu11==11.7.4.91
nvidia-nccl-cu11==2.14.3
nvidia-nvtx-cu11==11.7.91
sentencepiece==0.1.99
six==1.16.0
sympy==1.12
termcolor==2.3.0
torch==2.0.1
triton==2.0.0
typing_extensions==4.7.1
